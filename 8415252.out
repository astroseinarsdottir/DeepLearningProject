Running script

------------------------------------------------------------
Sender: LSF System <lsfadmin@n-62-20-2>
Subject: Job 8415252: <myJob> in cluster <dcc> Exited

Job <myJob> was submitted from host <gbarlogin2> by user <s153999> in cluster <dcc> at Mon Nov 23 14:08:02 2020
Job was executed on host(s) <n-62-20-2>, in queue <gpuv100>, as user <s153999> in cluster <dcc> at Mon Nov 23 14:08:55 2020
</zhome/bb/1/109600> was used as the home directory.
</zhome/bb/1/109600/DeepLearning/DeepLearningProject> was used as the working directory.
Started at Mon Nov 23 14:08:55 2020
Terminated at Mon Nov 23 14:09:02 2020
Results reported at Mon Nov 23 14:09:02 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -q gpuv100
#BSUB -gpu "num=1"
#BSUB -J myJob
#BSUB -n 1
#BSUB -W 10:00
#BSUB -R "rusage[mem=32GB]"
#BSUB -o %J.out
#BSUB -e %J.err

module load python3/3.8.0
module load cuda/8.0
module load cudnn/v7.0-prod-cuda8

unset PYTHONHOME
unset PYTHONPATH

export PATH="$HOME/.local/bin:$PATH"

cd ~/DeepLearning/DeepLearningProject

echo "Running script"
python3 training.py -total_steps 10e6 -num_levels 500

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1.29 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     32768.00 MB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   7 sec.
    Turnaround time :                            60 sec.

The output (if any) is above this job summary.



PS:

Read file <8415252.err> for stderr output of this job.

